{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89cc90fa-042a-453d-bdc9-748da6c7895b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:44.655724+00:00",
          "start_time": "2023-08-31T19:36:33.603461+00:00"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "8a34911d-a571-4349-82d0-9c36f7a6d7e7"
        }
      },
      "outputs": [],
      "source": "# pip install xgboost"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2420d2ad-14bd-41c5-b9ad-5ded77049b9e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:44.820413+00:00",
          "start_time": "2023-08-31T19:36:44.664043+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5165325-335f-44e0-a679-b6162300cbcc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:44.985786+00:00",
          "start_time": "2023-08-31T19:36:44.677813+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96bae00-fc1c-401f-a217-8469ea1f6130",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:45.151733+00:00",
          "start_time": "2023-08-31T19:36:44.826957+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2391f0f4-591f-4563-9887-5919e480042c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:45.318220+00:00",
          "start_time": "2023-08-31T19:36:44.996271+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e19b950-e43d-440b-a6e6-093f6b21360c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:45.481958+00:00",
          "start_time": "2023-08-31T19:36:45.159991+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a8ebf2-a2ae-4425-96b3-aed892bae124",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:50.962008+00:00",
          "start_time": "2023-08-31T19:36:45.598598+00:00"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "3990430c-6828-44a2-8b2b-e45b72db4a4f"
        }
      },
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1e4cfd-56ee-4493-86a1-8ff825f325bf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:51.204193+00:00",
          "start_time": "2023-08-31T19:36:51.002002+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ed1ef5b-565c-4b8a-828f-723ea9824a48",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:58.707160+00:00",
          "start_time": "2023-08-31T19:36:53.368005+00:00"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4adbc854-51a8-45e2-a321-24650da1ce35"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tslearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d0b5dda-c234-4061-9cf5-7293670da095",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:36:59.385291+00:00",
          "start_time": "2023-08-31T19:36:58.714839+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from tslearn.clustering import TimeSeriesKMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c8d371a-ceea-4457-af18-9552d438edcd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T18:27:38.163282+00:00",
          "start_time": "2023-08-30T18:22:32.119455+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "46ffa9ab-ce0d-4b39-a8d2-dcac12d27f2a"
        }
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('EDA4_nan820.csv')\n",
        "X = data.drop(['trending', 'Time'], axis=1)\n",
        "y = data['trending']\n",
        "\n",
        "# Split the data at line 820\n",
        "split_index = 820\n",
        "X_train = X.iloc[:split_index]\n",
        "X_test = X.iloc[split_index:]\n",
        "y_train = y.iloc[:split_index]\n",
        "y_test = y.iloc[split_index:]\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply Polynomial Feature Transformation\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly.fit_transform(X_train_scaled)\n",
        "X_test_poly = poly.transform(X_test_scaled)\n",
        "\n",
        "# Resample the training data using ADASYN\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_poly, y_train)\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3)\n",
        "grid_search.fit(X_train_adasyn, y_train_adasyn)\n",
        "best_clf = grid_search.best_estimator_\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred_proba = best_clf.predict_proba(X_test_poly)[:, 1]\n",
        "\n",
        "# Define thresholds\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "y_pred_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d0dc9b-d7b4-4fa2-92c5-a4f6f287f301",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T18:27:38.405482+00:00",
          "start_time": "2023-08-30T18:27:38.220361+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "d008dcfe-aa0c-478e-b155-1bdc97af35d2"
        }
      },
      "outputs": [],
      "source": [
        "# Predict on the training set using the best model\n",
        "y_train_pred_proba = best_clf.predict_proba(X_train_poly)[:, 1]\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold of 0.5\n",
        "y_train_pred = (y_train_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics for the training set\n",
        "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "precision_train = precision_score(y_train, y_train_pred)\n",
        "recall_train = recall_score(y_train, y_train_pred)\n",
        "f1_train = f1_score(y_train, y_train_pred)\n",
        "\n",
        "accuracy_train, precision_train, recall_train, f1_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d36329-34a8-4491-81d2-173268e4666d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T18:27:38.678565+00:00",
          "start_time": "2023-08-30T18:27:38.426770+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "677d66ff-b14e-4754-91dd-5031e748e6e2"
        }
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('EDA4_nan820.csv')\n",
        "X = data.drop(['trending', 'Time'], axis=1)\n",
        "y = data['trending']\n",
        "\n",
        "# Split the data at line 820\n",
        "split_index = 820\n",
        "X_train = X.iloc[:split_index]\n",
        "X_test = X.iloc[split_index:]\n",
        "y_train = y.iloc[:split_index]\n",
        "y_test = y.iloc[split_index:]\n",
        "\n",
        "# Preprocess the test data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_poly = poly.transform(X_test_scaled)\n",
        "\n",
        "# Predict using the trained model\n",
        "y_test_pred_proba = best_clf.predict_proba(X_test_poly)[:, 1]\n",
        "y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "y_test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ac2ad2-fcb4-47ca-809b-bb00f5b9d308",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T18:27:38.878502+00:00",
          "start_time": "2023-08-30T18:27:38.722251+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# # Combining the training and test data\n",
        "# combined_data = data.copy()\n",
        "# combined_data['Predicted_Trending'] = np.concatenate([y_train, y_test_pred])\n",
        "\n",
        "# # Saving the combined data to a CSV file\n",
        "# combined_data.to_csv('newAUG.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61a66ec-aac7-4074-b372-4b4f598d865e",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0d8cde-91b2-4501-b121-74d72ba4f98e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T18:34:55.418955+00:00",
          "start_time": "2023-08-30T18:27:38.888751+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Load the corrected data\n",
        "corrected_data = pd.read_csv('Corrected_Predictions_nan1190.csv')\n",
        "X_corrected = corrected_data.drop(['Corrected_Predictions', 'trending', 'Time'], axis=1)\n",
        "y_corrected = corrected_data['Corrected_Predictions']\n",
        "\n",
        "# Split the data at line 1190\n",
        "split_index_corrected = 1190\n",
        "X_train_corrected = X_corrected.iloc[:split_index_corrected]\n",
        "y_train_corrected = y_corrected.iloc[:split_index_corrected]\n",
        "\n",
        "# Scale the features\n",
        "scaler_corrected = StandardScaler()\n",
        "X_train_scaled_corrected = scaler_corrected.fit_transform(X_train_corrected)\n",
        "\n",
        "# Apply Polynomial Feature Transformation\n",
        "poly_corrected = PolynomialFeatures(degree=2)\n",
        "X_train_poly_corrected = poly_corrected.fit_transform(X_train_scaled_corrected)\n",
        "\n",
        "# Resample the training data using ADASYN\n",
        "adasyn_corrected = ADASYN(random_state=42)\n",
        "X_train_adasyn_corrected, y_train_adasyn_corrected = adasyn_corrected.fit_resample(X_train_poly_corrected, y_train_corrected)\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid_corrected = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search_corrected = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_corrected, cv=3)\n",
        "grid_search_corrected.fit(X_train_adasyn_corrected, y_train_adasyn_corrected)\n",
        "best_clf_corrected = grid_search_corrected.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32644e47-b1f3-47d5-b6ff-8483bf1968e5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T19:23:40.156004+00:00",
          "start_time": "2023-08-30T19:23:39.964000+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4dc60583-b36b-4cbc-b246-35e699977d03"
        }
      },
      "outputs": [],
      "source": [
        "# Predict using the retrained model on the training data\n",
        "y_pred_corrected = best_clf_corrected.predict(X_train_poly_corrected)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and f1 score\n",
        "accuracy_corrected = accuracy_score(y_train_corrected, y_pred_corrected)\n",
        "precision_corrected = precision_score(y_train_corrected, y_pred_corrected)\n",
        "recall_corrected = recall_score(y_train_corrected, y_pred_corrected)\n",
        "f1_corrected = f1_score(y_train_corrected, y_pred_corrected)\n",
        "\n",
        "accuracy_corrected, precision_corrected, recall_corrected, f1_corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c979257a-6663-428f-937c-c147fc5c1410",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T19:27:15.111821+00:00",
          "start_time": "2023-08-30T19:27:14.918529+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "ccc4b0a0-c6be-498f-8dfa-7f8e77f2ebee"
        }
      },
      "outputs": [],
      "source": [
        "# Predict using the retrained model on the test data\n",
        "y_pred_test = best_clf_corrected.predict(X_test_poly)\n",
        "\n",
        "# Since the test set target values are NaN, we can't calculate accuracy, precision, recall, and f1 score directly.\n",
        "# Instead, we'll return the predictions for further analysis.\n",
        "y_pred_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d6213d-cf7b-4273-8661-26bdb39931e7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T19:31:19.392711+00:00",
          "start_time": "2023-08-30T19:31:19.119592+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "a6c9c972-759e-40a7-9930-b4b3c1395e32"
        }
      },
      "outputs": [],
      "source": [
        "# Load the corrected data\n",
        "data_corrected = pd.read_csv('Corrected_Predictions_nan1190.csv')\n",
        "\n",
        "# Add the training predictions to the 'Model_Predictions' column\n",
        "data_corrected.loc[:split_index-1, 'Model_Predictions'] = y_train_corrected\n",
        "\n",
        "# Add the test predictions to the 'Model_Predictions' column\n",
        "data_corrected.loc[split_index:, 'Model_Predictions'] = y_pred_test\n",
        "\n",
        "# Save the combined dataset with predictions to a new CSV file\n",
        "data_corrected.to_csv('analyse.csv', index=False)\n",
        "\n",
        "'analyse.csv saved successfully.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed977025-667a-432a-802e-40e1c077816c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T19:39:25.053195+00:00",
          "start_time": "2023-08-30T19:39:24.862471+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "61ff6e9c-fd48-40da-bff8-23e5d7a11b2a"
        }
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "model_filename = 'Retrained_trending_modelAUG30.pkl'\n",
        "joblib.dump(best_clf, model_filename)\n",
        "\n",
        "f'Model saved as {model_filename}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d082f49-3b3f-4a63-bd50-fc4391d111e9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T21:01:00.243619+00:00",
          "start_time": "2023-08-30T20:52:05.288463+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "05fb7df4-c4dd-4c83-a83c-09ebca6ba65e"
        }
      },
      "outputs": [],
      "source": [
        "# Modified hyperparameter grid\n",
        "param_grid_modified = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'max_depth': [None, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV with the modified parameter grid\n",
        "grid_search_modified = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_modified, cv=3)\n",
        "grid_search_modified.fit(X_train_adasyn, y_train_adasyn)\n",
        "best_clf_modified = grid_search_modified.best_estimator_\n",
        "\n",
        "# Display the best parameters from the grid search\n",
        "grid_search_modified.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf93be5-201c-484a-806b-f7ac9e7a5fd6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T23:08:49.652404+00:00",
          "start_time": "2023-08-30T22:17:45.820106+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('EDA4_nan820.csv')\n",
        "X = data.drop(['trending', 'Time'], axis=1)\n",
        "y = data['trending']\n",
        "\n",
        "# Split the data at line 820\n",
        "split_index = 820\n",
        "X_train = X.iloc[:split_index]\n",
        "X_test = X.iloc[split_index:]\n",
        "y_train = y.iloc[:split_index]\n",
        "y_test = y.iloc[split_index:]\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply Polynomial Feature Transformation\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly.fit_transform(X_train_scaled)\n",
        "X_test_poly = poly.transform(X_test_scaled)\n",
        "\n",
        "# Resample the training data using ADASYN\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_poly, y_train)\n",
        "\n",
        "# Train RandomForest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3)\n",
        "grid_search_rf.fit(X_train_adasyn, y_train_adasyn)\n",
        "best_rf = grid_search_rf.best_estimator_\n",
        "\n",
        "# Train XGBoost with custom loss function for trend length\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # Calculate the difference between consecutive predictions\n",
        "    diff = np.diff(y_pred)\n",
        "    # Penalize short trends\n",
        "    penalty = np.sum(np.abs(diff))\n",
        "    # Standard log loss\n",
        "    log_loss = -np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return log_loss + penalty\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'alpha': [0, 0.1, 1],\n",
        "    'lambda': [0, 0.1, 1]\n",
        "}\n",
        "grid_search_xgb = GridSearchCV(xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42), param_grid_xgb, cv=3)\n",
        "grid_search_xgb.fit(X_train_adasyn, y_train_adasyn)\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "\n",
        "# Ensemble the models using VotingClassifier\n",
        "ensemble_model = VotingClassifier(estimators=[('rf', best_rf), ('xgb', best_xgb)], voting='soft')\n",
        "ensemble_model.fit(X_train_adasyn, y_train_adasyn)\n",
        "\n",
        "# Predictions from the ensemble model\n",
        "y_train_pred_ensemble = ensemble_model.predict(X_train_poly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5679d82f-48cb-4525-82e1-eee6ff546164",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T23:38:24.327928+00:00",
          "start_time": "2023-08-30T23:38:23.826061+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "dbc150d6-a2c3-4fae-bd7d-0587a7e2e49e"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extracting the actual and predicted values\n",
        "actual_values = y_train\n",
        "predicted_values = y_train_pred_ensemble\n",
        "\n",
        "# Plotting the actual vs predicted values\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.plot(actual_values.values, label='Actual Trending Values', color='blue')\n",
        "plt.plot(predicted_values, label='Predicted Trending Values', color='red', linestyle='dashed')\n",
        "plt.title('Actual vs Predicted Trending Values')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Trending Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1d6122-e151-4f07-98f3-7c35c134417f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T23:46:33.464278+00:00",
          "start_time": "2023-08-30T23:46:33.220695+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Preprocess the test data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_test_poly = poly.transform(X_test_scaled)\n",
        "\n",
        "# Predict using the ensemble model\n",
        "y_test_pred_ensemble = ensemble_model.predict(X_test_poly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7fb87da-6543-457d-82f9-e0d97d974c3a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T23:50:53.909414+00:00",
          "start_time": "2023-08-30T23:50:53.420521+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "8aa6f974-78ae-453a-b7ea-f9a4ca9393fd"
        }
      },
      "outputs": [],
      "source": [
        "# Plotting the ensemble model predictions for the test set\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.plot(y_test.index, y_test_pred_ensemble, label='Predicted Trending Values', color='blue')\n",
        "plt.title('Ensemble Model Predictions for Test Set')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Trending')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd93deb-2404-402e-8841-fb3154dcded9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T23:52:19.012364+00:00",
          "start_time": "2023-08-30T23:52:18.747575+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "e871560a-a561-45a0-887f-1b43b3b0a621"
        }
      },
      "outputs": [],
      "source": [
        "# Concatenate the training and test data\n",
        "full_data = pd.concat([X_train, X_test])\n",
        "full_data['Actual_Trending'] = pd.concat([y_train, y_test])\n",
        "full_data['Ensemble_Predictions'] = np.concatenate([y_train_pred_ensemble, y_test_pred_ensemble])\n",
        "\n",
        "# Save the dataframe to a CSV file\n",
        "full_data.to_csv('ensamble_analyse.csv', index=False)\n",
        "\n",
        "'ensamble_analyse.csv saved successfully.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "466340fb-58cb-4948-8f88-e84e9650cb30",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-30T23:52:41.133593+00:00",
          "start_time": "2023-08-30T23:52:40.903839+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "72991cf3-9cbb-4283-861f-9fd1ab40c87b"
        }
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the ensemble model to a file\n",
        "joblib.dump(ensemble_model, 'hybrid_ensamble.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5206be8-d11c-46ab-9f53-54664629349f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:37:16.622095+00:00",
          "start_time": "2023-08-31T19:37:16.383504+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "ensemble_model = load('hybrid_ensamble.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bdc79c7-f5e2-4d40-97a3-0dce9eafe9c4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:44:27.892921+00:00",
          "start_time": "2023-08-31T19:43:48.783816+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4014dd2c-3111-465e-87e2-5b23db432493"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Corrected_Predictions_nan1190.csv')\n",
        "X = data.drop(['Corrected_Predictions', 'Time', 'trending'], axis=1)\n",
        "y = data['Corrected_Predictions']\n",
        "\n",
        "# Split the data at line 1190\n",
        "split_index = 1190\n",
        "X_train = X.iloc[:split_index]\n",
        "y_train = y.iloc[:split_index]\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply Polynomial Feature Transformation\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly.fit_transform(X_train_scaled)\n",
        "\n",
        "# Resample the training data using ADASYN\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_poly, y_train)\n",
        "\n",
        "# Train RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train_adasyn, y_train_adasyn)\n",
        "\n",
        "# Train XGBoost\n",
        "def custom_loss(y_pred, dtrain):\n",
        "    y_true = dtrain.get_label()\n",
        "    grad = np.where(y_true == 1, -2*(1-y_pred), 2*y_pred)\n",
        "    hess = np.where(y_true == 1, 2*y_pred, 2*(1-y_pred))\n",
        "    return grad, hess\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train_adasyn, label=y_train_adasyn)\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'max_depth': 6,\n",
        "    'eta': 0.1,\n",
        "    'alpha': 1,\n",
        "    'lambda': 1\n",
        "}\n",
        "bst = xgb.train(params, dtrain, num_boost_round=1000, obj=custom_loss)\n",
        "\n",
        "# Ensemble predictions\n",
        "class EnsembleModel:\n",
        "    def __init__(self, model1, model2):\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict trend length with XGBoost\n",
        "        trend_length_pred = self.model2.predict(xgb.DMatrix(X))\n",
        "        # Use trend length prediction to adjust RandomForest predictions\n",
        "        rf_pred = self.model1.predict(X)\n",
        "        adjusted_pred = np.where(trend_length_pred > 0.5, rf_pred, 0)\n",
        "        return adjusted_pred\n",
        "\n",
        "ensemble_model = EnsembleModel(rf_clf, bst)\n",
        "y_train_pred_ensemble = ensemble_model.predict(X_train_poly)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_train, y_train_pred_ensemble)\n",
        "precision = precision_score(y_train, y_train_pred_ensemble)\n",
        "recall = recall_score(y_train, y_train_pred_ensemble)\n",
        "f1 = f1_score(y_train, y_train_pred_ensemble)\n",
        "\n",
        "accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1288bd93-f5f1-4359-a72d-8c863583a490",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T19:48:17.301686+00:00",
          "start_time": "2023-08-31T19:48:16.758731+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "bbd26e5f-d321-427e-b904-e17912fc993f"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(y_train.values, label='Actual Values', color='blue')\n",
        "plt.plot(y_train_pred_ensemble, label='Predicted Values', color='red', linestyle='--')\n",
        "plt.title('Actual vs Predicted Values')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a21bb1-4f00-4d06-bcc7-65d19ce60390",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:00:37.647842+00:00",
          "start_time": "2023-08-31T20:00:37.485067+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "361b4a37-fa57-49cb-a1fd-12648660a32c"
        }
      },
      "outputs": [],
      "source": [
        "# Check the number of non-NaN and NaN values in y_test\n",
        "non_nan_count = y_test.dropna().shape[0]\n",
        "nan_count = y_test.isna().sum()\n",
        "non_nan_count, nan_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2bab75c-c469-4f64-9eb3-2aec2cf4a808",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:01:41.049812+00:00",
          "start_time": "2023-08-31T20:01:40.886475+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "e27ef034-34be-460d-a53f-2273772b5af6"
        }
      },
      "outputs": [],
      "source": [
        "# Check the shape and first few rows of X_test\n",
        "X_test.shape, X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf3d719-e3dc-46ff-a76b-64f8a669f3ad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:02:19.385445+00:00",
          "start_time": "2023-08-31T20:02:19.085891+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "94ba91b5-bec7-4cbe-8cb8-2feac37d19db"
        }
      },
      "outputs": [],
      "source": [
        "# Load the data from 'Corrected_Predictions_nan1190.csv'\n",
        "data_corrected = pd.read_csv('Corrected_Predictions_nan1190.csv')\n",
        "X_corrected = data_corrected.drop(['Corrected_Predictions', 'Time', 'trending'], axis=1)\n",
        "y_corrected = data_corrected['Corrected_Predictions']\n",
        "# Extract rows with NaN values in y_corrected for prediction\n",
        "X_missing_corrected = X_corrected[y_corrected.isna()]\n",
        "# Predict values for the missing data\n",
        "y_missing_pred_corrected = ensemble_model.predict(poly.transform(scaler.transform(X_missing_corrected)))\n",
        "y_missing_pred_corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae88b03-c1c8-4171-a29c-e1bda75646ec",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:05:33.639562+00:00",
          "start_time": "2023-08-31T20:05:33.152108+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "86208c92-c0d0-4604-9616-37a48066ff6e"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(y_missing_pred_corrected, label='Predicted Values', color='red')\n",
        "plt.title('Predicted Values for Missing Data')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e8b3493-fee2-4284-af6d-4bbd868bf62e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:07:25.425665+00:00",
          "start_time": "2023-08-31T20:07:25.182574+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Add the predicted values to the 'Corrected_Predictions' column for the rows with NaN values\n",
        "data_corrected.loc[y_corrected.isna(), 'Corrected_Predictions'] = y_missing_pred_corrected\n",
        "# Save the updated dataset to 'hybrid2.csv'\n",
        "data_corrected.to_csv('hybrid2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4038b5fe-c81e-48ad-95f4-d5acaf9d08fc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:17:41.315148+00:00",
          "start_time": "2023-08-31T20:17:40.584950+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "a6f8efa0-fc47-40de-acb7-3c3e326f3e70"
        }
      },
      "outputs": [],
      "source": [
        "# Reload necessary libraries and data\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the new CSV data into a DataFrame\n",
        "data_aug = pd.read_csv('hybrid2.csv')\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plot the Open, High, Low, Close columns\n",
        "data_aug[['Open', 'High', 'Low', 'Close']].plot(ax=plt.gca(), title='OHLC Chart with Predicted_Trending')\n",
        "\n",
        "# Create a secondary y-axis to plot the 'Predicted_Trending' column\n",
        "data_aug['Corrected_Predictions'].plot(secondary_y=True, style='g', ax=plt.gca(), alpha=0.7, label='Predicted_Trending')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f9b8ac4-83b3-4672-aa71-d5e7e00a7e51",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:19:58.067648+00:00",
          "start_time": "2023-08-31T20:19:57.349892+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "09ef07dc-ecfa-448c-a5f7-8458402d34eb"
        }
      },
      "outputs": [],
      "source": [
        "# Remove the first 820 rows from the dataframe\n",
        "data_aug_trimmed = data_aug.iloc[820:].reset_index(drop=True)\n",
        "\n",
        "# Plot the trimmed data\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plot the Open, High, Low, Close columns\n",
        "data_aug_trimmed[['Open', 'High', 'Low', 'Close']].plot(ax=plt.gca(), title='OHLC Chart with Predicted_Trending (After removing first 820 rows)')\n",
        "\n",
        "# Create a secondary y-axis to plot the 'Predicted_Trending' column\n",
        "data_aug_trimmed['Corrected_Predictions'].plot(secondary_y=True, style='g', ax=plt.gca(), alpha=0.7, label='Predicted_Trending')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a42d19-24c6-4d5d-8906-bc78b818fc1d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:22:30.819113+00:00",
          "start_time": "2023-08-31T20:22:30.140649+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "494739a4-1f11-4c21-ba6a-997d43517d51"
        }
      },
      "outputs": [],
      "source": [
        "# Zoom in to the first 100 data points after removing the initial 820 rows\n",
        "data_aug_zoomed = data_aug_trimmed.iloc[:300]\n",
        "\n",
        "# Plot the zoomed-in data\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plot the Open, High, Low, Close columns\n",
        "data_aug_zoomed[['Open', 'High', 'Low', 'Close']].plot(ax=plt.gca(), title='OHLC Chart (Zoomed to first 100 data points) with Predicted_Trending')\n",
        "\n",
        "# Create a secondary y-axis to plot the 'Predicted_Trending' column\n",
        "data_aug_zoomed['Corrected_Predictions'].plot(secondary_y=True, style='g', ax=plt.gca(), alpha=0.7, label='Predicted_Trending')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ddb08f-5b65-4312-a7ac-97c7cbb02498",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-08-31T20:26:07.331105+00:00",
          "start_time": "2023-08-31T20:26:07.084340+00:00"
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "2ae9e576-cc43-46c0-96d2-7b9bc72b6cda"
        }
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "# Save the ensemble model to a file\n",
        "joblib.dump(ensemble_model, 'hybrid_second_training.pkl')"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "noteable": {
      "last_delta_id": "ade68db4-c576-4b0f-baab-053134c8c991",
      "last_transaction_id": "9c81ed63-9934-4fb9-a05e-f25ca8df4dde"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "0d94d139-3e85-5185-9a95-fe0611a4bc52",
        "openai_ephemeral_user_id": "b0d4d36c-935f-58e3-950b-5fa2656f903a",
        "openai_subdivision1_iso_code": "US-MA"
      }
    },
    "nteract": {
      "version": "noteable@2.9.0"
    },
    "selected_hardware_size": "large"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}